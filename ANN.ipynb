{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "## print shape of dataset with row\n",
    "train['train_or_test']='train'\n",
    "test['train_or_test']='test'\n",
    "dataset=train.append(test)\n",
    "# let's make a function to create 3 variables from Age:\n",
    "# 1-e filling NA with median, 2- random sampling or 3- zeroes\n",
    "\n",
    "def impute_na(df, variable, median,mean):\n",
    "    df[variable+'_NA'] = np.where(df[variable].isnull(), 1, 0)\n",
    "    df[variable+'_median'] = df[variable].fillna(median)\n",
    "    df[variable+'_mean'] = df[variable].fillna(mean)\n",
    "    # random sampling\n",
    "    df[variable+'_random'] = df[variable]\n",
    "    # extract the random sample to fill the na\n",
    "    random_sample = dataset[variable].dropna().sample(df[variable].isnull().sum(), random_state=0)\n",
    "    # pandas needs to have the same index in order to merge datasets\n",
    "    random_sample.index = df[df[variable].isnull()].index\n",
    "    df.loc[df[variable].isnull(), variable+'_random'] = random_sample\n",
    "    \n",
    "    \n",
    "median=dataset.Number_Weeks_Used.median()\n",
    "mean=dataset.Number_Weeks_Used.mean()\n",
    "impute_na(dataset, 'Number_Weeks_Used', median, mean)\n",
    "\n",
    "dataset['Crop_Soil']=dataset['Crop_Type']+dataset['Soil_Type']\n",
    "\n",
    "dataset['Doses_given']=dataset['Number_Doses_Week']*dataset['Number_Weeks_Used_random']\n",
    "dataset['Doses_missed']=dataset['Number_Doses_Week']*dataset['Number_Weeks_Quit']\n",
    "\n",
    "ohe1=pd.get_dummies(dataset[ 'Pesticide_Use_Category'],prefix='Pest_Cat_', drop_first=True)\n",
    "\n",
    "ohe2 = pd.get_dummies(dataset[ 'Season'],prefix='Season_Cat_', drop_first=True)\n",
    "\n",
    "final_ohe = pd.concat([dataset, ohe1, ohe2], axis=1, sort=False)\n",
    "\n",
    "trn = final_ohe.loc[final_ohe['train_or_test']=='train', :]\n",
    "tst = final_ohe.loc[final_ohe['train_or_test']=='test', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn=trn[['Estimated_Insects_Count','Number_Doses_Week','Number_Weeks_Used_median', 'Pesticide_Use_Category',\n",
    "       'Number_Weeks_Quit','Soil_Type','Crop_Type','Season']]\n",
    "y=trn['Crop_Damage']\n",
    "X_tst=tst[['Estimated_Insects_Count','Number_Doses_Week','Number_Weeks_Used_median', 'Pesticide_Use_Category',\n",
    "       'Number_Weeks_Quit','Soil_Type','Crop_Type','Season']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trn, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-088f577e8541>:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=8, units=6, kernel_initializer=\"he_uniform\")`\n",
      "  classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu',input_dim = 8))\n",
      "<ipython-input-13-088f577e8541>:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"he_uniform\")`\n",
      "  classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu'))\n",
      "<ipython-input-13-088f577e8541>:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\")`\n",
      "  classifier.add(Dense(output_dim = 1, init = 'glorot_uniform', activation = 'sigmoid'))\n",
      "<ipython-input-13-088f577e8541>:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, nb_epoch = 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47627 samples, validate on 23459 samples\n",
      "Epoch 1/100\n",
      "47627/47627 [==============================] - 7s 144us/step - loss: 0.4509 - accuracy: 0.8221 - val_loss: 0.4110 - val_accuracy: 0.8278\n",
      "Epoch 2/100\n",
      "47627/47627 [==============================] - 5s 101us/step - loss: 0.4032 - accuracy: 0.8254 - val_loss: 0.3943 - val_accuracy: 0.8248\n",
      "Epoch 3/100\n",
      "47627/47627 [==============================] - 5s 100us/step - loss: 0.3922 - accuracy: 0.8251 - val_loss: 0.3873 - val_accuracy: 0.8278\n",
      "Epoch 4/100\n",
      "47627/47627 [==============================] - 5s 100us/step - loss: 0.3866 - accuracy: 0.8265 - val_loss: 0.3831 - val_accuracy: 0.8280\n",
      "Epoch 5/100\n",
      "47627/47627 [==============================] - 5s 104us/step - loss: 0.3832 - accuracy: 0.8270 - val_loss: 0.3810 - val_accuracy: 0.8254\n",
      "Epoch 6/100\n",
      "47627/47627 [==============================] - 5s 95us/step - loss: 0.3806 - accuracy: 0.8279 - val_loss: 0.3776 - val_accuracy: 0.8295\n",
      "Epoch 7/100\n",
      "47627/47627 [==============================] - 5s 96us/step - loss: 0.3787 - accuracy: 0.8284 - val_loss: 0.3756 - val_accuracy: 0.8306\n",
      "Epoch 8/100\n",
      "47627/47627 [==============================] - 4s 93us/step - loss: 0.3767 - accuracy: 0.8286 - val_loss: 0.3744 - val_accuracy: 0.8291\n",
      "Epoch 9/100\n",
      "47627/47627 [==============================] - 5s 96us/step - loss: 0.3749 - accuracy: 0.8287 - val_loss: 0.3746 - val_accuracy: 0.8247\n",
      "Epoch 10/100\n",
      "47627/47627 [==============================] - 5s 101us/step - loss: 0.3735 - accuracy: 0.8291 - val_loss: 0.3725 - val_accuracy: 0.8275\n",
      "Epoch 11/100\n",
      "47627/47627 [==============================] - 7s 138us/step - loss: 0.3722 - accuracy: 0.8289 - val_loss: 0.3703 - val_accuracy: 0.8298\n",
      "Epoch 12/100\n",
      "47627/47627 [==============================] - 9s 191us/step - loss: 0.3710 - accuracy: 0.8287 - val_loss: 0.3694 - val_accuracy: 0.8284\n",
      "Epoch 13/100\n",
      "47627/47627 [==============================] - 8s 178us/step - loss: 0.3699 - accuracy: 0.8285 - val_loss: 0.3684 - val_accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "47627/47627 [==============================] - 5s 106us/step - loss: 0.3687 - accuracy: 0.8289 - val_loss: 0.3678 - val_accuracy: 0.8278\n",
      "Epoch 15/100\n",
      "47627/47627 [==============================] - 5s 102us/step - loss: 0.3675 - accuracy: 0.8284 - val_loss: 0.3659 - val_accuracy: 0.8337\n",
      "Epoch 16/100\n",
      "47627/47627 [==============================] - 5s 104us/step - loss: 0.3659 - accuracy: 0.8294 - val_loss: 0.3656 - val_accuracy: 0.8275\n",
      "Epoch 17/100\n",
      "47627/47627 [==============================] - 5s 104us/step - loss: 0.3643 - accuracy: 0.8288 - val_loss: 0.3646 - val_accuracy: 0.8312\n",
      "Epoch 18/100\n",
      "47627/47627 [==============================] - 5s 96us/step - loss: 0.3626 - accuracy: 0.8292 - val_loss: 0.3627 - val_accuracy: 0.8352\n",
      "Epoch 19/100\n",
      "47627/47627 [==============================] - 4s 93us/step - loss: 0.3613 - accuracy: 0.8296 - val_loss: 0.3615 - val_accuracy: 0.8291\n",
      "Epoch 20/100\n",
      "47627/47627 [==============================] - 5s 115us/step - loss: 0.3595 - accuracy: 0.8294 - val_loss: 0.3603 - val_accuracy: 0.8323\n",
      "Epoch 21/100\n",
      "47627/47627 [==============================] - 7s 150us/step - loss: 0.3578 - accuracy: 0.8294 - val_loss: 0.3588 - val_accuracy: 0.8350\n",
      "Epoch 22/100\n",
      "47627/47627 [==============================] - 9s 195us/step - loss: 0.3556 - accuracy: 0.8295 - val_loss: 0.3580 - val_accuracy: 0.8332\n",
      "Epoch 23/100\n",
      "47627/47627 [==============================] - 9s 189us/step - loss: 0.3539 - accuracy: 0.8286 - val_loss: 0.3565 - val_accuracy: 0.8346\n",
      "Epoch 24/100\n",
      "47627/47627 [==============================] - 9s 188us/step - loss: 0.3519 - accuracy: 0.8290 - val_loss: 0.3558 - val_accuracy: 0.8292\n",
      "Epoch 25/100\n",
      "47627/47627 [==============================] - 9s 194us/step - loss: 0.3498 - accuracy: 0.8289 - val_loss: 0.3540 - val_accuracy: 0.8277\n",
      "Epoch 26/100\n",
      "47627/47627 [==============================] - 8s 160us/step - loss: 0.3476 - accuracy: 0.8287 - val_loss: 0.3520 - val_accuracy: 0.8322\n",
      "Epoch 27/100\n",
      "47627/47627 [==============================] - 5s 98us/step - loss: 0.3452 - accuracy: 0.8290 - val_loss: 0.3502 - val_accuracy: 0.8324\n",
      "Epoch 28/100\n",
      "47627/47627 [==============================] - 5s 98us/step - loss: 0.3431 - accuracy: 0.8287 - val_loss: 0.3486 - val_accuracy: 0.8334\n",
      "Epoch 29/100\n",
      "47627/47627 [==============================] - 5s 95us/step - loss: 0.3404 - accuracy: 0.8288 - val_loss: 0.3469 - val_accuracy: 0.8324\n",
      "Epoch 30/100\n",
      "47627/47627 [==============================] - 4s 93us/step - loss: 0.3383 - accuracy: 0.8289 - val_loss: 0.3465 - val_accuracy: 0.8289\n",
      "Epoch 31/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: 0.3358 - accuracy: 0.8294 - val_loss: 0.3444 - val_accuracy: 0.8298\n",
      "Epoch 32/100\n",
      "47627/47627 [==============================] - 4s 92us/step - loss: 0.3330 - accuracy: 0.8287 - val_loss: 0.3433 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "47627/47627 [==============================] - 4s 92us/step - loss: 0.3301 - accuracy: 0.8291 - val_loss: 0.3405 - val_accuracy: 0.8297 accuracy: 0.82 - ETA: 0s - l\n",
      "Epoch 34/100\n",
      "47627/47627 [==============================] - 5s 103us/step - loss: 0.3277 - accuracy: 0.8281 - val_loss: 0.3390 - val_accuracy: 0.8332\n",
      "Epoch 35/100\n",
      "47627/47627 [==============================] - 9s 186us/step - loss: 0.3244 - accuracy: 0.8290 - val_loss: 0.3363 - val_accuracy: 0.8312\n",
      "Epoch 36/100\n",
      "47627/47627 [==============================] - 9s 183us/step - loss: 0.3212 - accuracy: 0.8285 - val_loss: 0.3343 - val_accuracy: 0.8327\n",
      "Epoch 37/100\n",
      "47627/47627 [==============================] - 7s 156us/step - loss: 0.3176 - accuracy: 0.8283 - val_loss: 0.3326 - val_accuracy: 0.8353\n",
      "Epoch 38/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: 0.3143 - accuracy: 0.8290 - val_loss: 0.3308 - val_accuracy: 0.8292\n",
      "Epoch 39/100\n",
      "47627/47627 [==============================] - 4s 90us/step - loss: 0.3105 - accuracy: 0.8287 - val_loss: 0.3268 - val_accuracy: 0.8316\n",
      "Epoch 40/100\n",
      "47627/47627 [==============================] - 4s 88us/step - loss: 0.3072 - accuracy: 0.8284 - val_loss: 0.3245 - val_accuracy: 0.8302\n",
      "Epoch 41/100\n",
      "47627/47627 [==============================] - 4s 90us/step - loss: 0.3031 - accuracy: 0.8282 - val_loss: 0.3211 - val_accuracy: 0.8316\n",
      "Epoch 42/100\n",
      "47627/47627 [==============================] - 4s 94us/step - loss: 0.2989 - accuracy: 0.8287 - val_loss: 0.3178 - val_accuracy: 0.8317\n",
      "Epoch 43/100\n",
      "47627/47627 [==============================] - 5s 95us/step - loss: 0.2945 - accuracy: 0.8278 - val_loss: 0.3155 - val_accuracy: 0.8271\n",
      "Epoch 44/100\n",
      "47627/47627 [==============================] - 8s 176us/step - loss: 0.2896 - accuracy: 0.8284 - val_loss: 0.3134 - val_accuracy: 0.8360\n",
      "Epoch 45/100\n",
      "47627/47627 [==============================] - 9s 188us/step - loss: 0.2850 - accuracy: 0.8274 - val_loss: 0.3088 - val_accuracy: 0.8286\n",
      "Epoch 46/100\n",
      "47627/47627 [==============================] - 8s 158us/step - loss: 0.2800 - accuracy: 0.8294 - val_loss: 0.3056 - val_accuracy: 0.8331\n",
      "Epoch 47/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: 0.2753 - accuracy: 0.8282 - val_loss: 0.3021 - val_accuracy: 0.8296\n",
      "Epoch 48/100\n",
      "47627/47627 [==============================] - 5s 96us/step - loss: 0.2699 - accuracy: 0.8284 - val_loss: 0.2990 - val_accuracy: 0.8264\n",
      "Epoch 49/100\n",
      "47627/47627 [==============================] - 4s 93us/step - loss: 0.2642 - accuracy: 0.8281 - val_loss: 0.2949 - val_accuracy: 0.8274\n",
      "Epoch 50/100\n",
      "47627/47627 [==============================] - 4s 94us/step - loss: 0.2586 - accuracy: 0.8278 - val_loss: 0.2913 - val_accuracy: 0.8260\n",
      "Epoch 51/100\n",
      "47627/47627 [==============================] - 4s 94us/step - loss: 0.2530 - accuracy: 0.8274 - val_loss: 0.2852 - val_accuracy: 0.8317\n",
      "Epoch 52/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: 0.2464 - accuracy: 0.8282 - val_loss: 0.2862 - val_accuracy: 0.8199\n",
      "Epoch 53/100\n",
      "47627/47627 [==============================] - 4s 89us/step - loss: 0.2405 - accuracy: 0.8273 - val_loss: 0.2767 - val_accuracy: 0.8297\n",
      "Epoch 54/100\n",
      "47627/47627 [==============================] - 5s 107us/step - loss: 0.2342 - accuracy: 0.8280 - val_loss: 0.2730 - val_accuracy: 0.8260\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47627/47627 [==============================] - 4s 85us/step - loss: 0.2271 - accuracy: 0.8276 - val_loss: 0.2699 - val_accuracy: 0.8276\n",
      "Epoch 56/100\n",
      "47627/47627 [==============================] - 4s 89us/step - loss: 0.2202 - accuracy: 0.8269 - val_loss: 0.2620 - val_accuracy: 0.8291\n",
      "Epoch 57/100\n",
      "47627/47627 [==============================] - 4s 93us/step - loss: 0.2131 - accuracy: 0.8288 - val_loss: 0.2616 - val_accuracy: 0.8202\n",
      "Epoch 58/100\n",
      "47627/47627 [==============================] - 5s 95us/step - loss: 0.2059 - accuracy: 0.8273 - val_loss: 0.2522 - val_accuracy: 0.8314\n",
      "Epoch 59/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: 0.1979 - accuracy: 0.8268 - val_loss: 0.2488 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "47627/47627 [==============================] - 4s 85us/step - loss: 0.1897 - accuracy: 0.8268 - val_loss: 0.2415 - val_accuracy: 0.8315\n",
      "Epoch 61/100\n",
      "47627/47627 [==============================] - 4s 88us/step - loss: 0.1823 - accuracy: 0.8269 - val_loss: 0.2364 - val_accuracy: 0.8262\n",
      "Epoch 62/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: 0.1733 - accuracy: 0.8273 - val_loss: 0.2297 - val_accuracy: 0.8283\n",
      "Epoch 63/100\n",
      "47627/47627 [==============================] - 4s 89us/step - loss: 0.1641 - accuracy: 0.8282 - val_loss: 0.2227 - val_accuracy: 0.8300\n",
      "Epoch 64/100\n",
      "47627/47627 [==============================] - 5s 96us/step - loss: 0.1547 - accuracy: 0.8273 - val_loss: 0.2175 - val_accuracy: 0.8237\n",
      "Epoch 65/100\n",
      "47627/47627 [==============================] - 9s 182us/step - loss: 0.1459 - accuracy: 0.8278 - val_loss: 0.2100 - val_accuracy: 0.8332\n",
      "Epoch 66/100\n",
      "47627/47627 [==============================] - 9s 184us/step - loss: 0.1363 - accuracy: 0.8276 - val_loss: 0.2046 - val_accuracy: 0.8263\n",
      "Epoch 67/100\n",
      "47627/47627 [==============================] - 8s 161us/step - loss: 0.1262 - accuracy: 0.8276 - val_loss: 0.1962 - val_accuracy: 0.8293\n",
      "Epoch 68/100\n",
      "47627/47627 [==============================] - 5s 95us/step - loss: 0.1160 - accuracy: 0.8270 - val_loss: 0.1901 - val_accuracy: 0.8274\n",
      "Epoch 69/100\n",
      "47627/47627 [==============================] - 5s 96us/step - loss: 0.1060 - accuracy: 0.8275 - val_loss: 0.1819 - val_accuracy: 0.8312\n",
      "Epoch 70/100\n",
      "47627/47627 [==============================] - 4s 93us/step - loss: 0.0954 - accuracy: 0.8275 - val_loss: 0.1756 - val_accuracy: 0.8277\n",
      "Epoch 71/100\n",
      "47627/47627 [==============================] - 4s 93us/step - loss: 0.0842 - accuracy: 0.8262 - val_loss: 0.1664 - val_accuracy: 0.8286\n",
      "Epoch 72/100\n",
      "47627/47627 [==============================] - 4s 90us/step - loss: 0.0734 - accuracy: 0.8271 - val_loss: 0.1598 - val_accuracy: 0.8336\n",
      "Epoch 73/100\n",
      "47627/47627 [==============================] - 4s 89us/step - loss: 0.0617 - accuracy: 0.8275 - val_loss: 0.1534 - val_accuracy: 0.8270\n",
      "Epoch 74/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: 0.0515 - accuracy: 0.8266 - val_loss: 0.1440 - val_accuracy: 0.8339\n",
      "Epoch 75/100\n",
      "47627/47627 [==============================] - 4s 90us/step - loss: 0.0393 - accuracy: 0.8268 - val_loss: 0.1381 - val_accuracy: 0.8221\n",
      "Epoch 76/100\n",
      "47627/47627 [==============================] - 4s 90us/step - loss: 0.0269 - accuracy: 0.8268 - val_loss: 0.1269 - val_accuracy: 0.8322\n",
      "Epoch 77/100\n",
      "47627/47627 [==============================] - 4s 88us/step - loss: 0.0136 - accuracy: 0.8270 - val_loss: 0.1179 - val_accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "47627/47627 [==============================] - 4s 92us/step - loss: 0.0012 - accuracy: 0.8271 - val_loss: 0.1096 - val_accuracy: 0.8262\n",
      "Epoch 79/100\n",
      "47627/47627 [==============================] - 4s 94us/step - loss: -0.0130 - accuracy: 0.8261 - val_loss: 0.1019 - val_accuracy: 0.8372\n",
      "Epoch 80/100\n",
      "47627/47627 [==============================] - 8s 171us/step - loss: -0.0267 - accuracy: 0.8275 - val_loss: 0.0905 - val_accuracy: 0.8299\n",
      "Epoch 81/100\n",
      "47627/47627 [==============================] - 8s 175us/step - loss: -0.0404 - accuracy: 0.8269 - val_loss: 0.0809 - val_accuracy: 0.8299\n",
      "Epoch 82/100\n",
      "47627/47627 [==============================] - 4s 85us/step - loss: -0.0545 - accuracy: 0.8257 - val_loss: 0.0696 - val_accuracy: 0.8258\n",
      "Epoch 83/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: -0.0693 - accuracy: 0.8269 - val_loss: 0.0615 - val_accuracy: 0.8337\n",
      "Epoch 84/100\n",
      "47627/47627 [==============================] - 4s 85us/step - loss: -0.0831 - accuracy: 0.8269 - val_loss: 0.0523 - val_accuracy: 0.8326\n",
      "Epoch 85/100\n",
      "47627/47627 [==============================] - 4s 86us/step - loss: -0.0962 - accuracy: 0.8276 - val_loss: 0.0458 - val_accuracy: 0.8213\n",
      "Epoch 86/100\n",
      "47627/47627 [==============================] - 4s 86us/step - loss: -0.1102 - accuracy: 0.8279 - val_loss: 0.0317 - val_accuracy: 0.8284\n",
      "Epoch 87/100\n",
      "47627/47627 [==============================] - 5s 97us/step - loss: -0.1275 - accuracy: 0.8280 - val_loss: 0.0235 - val_accuracy: 0.82381750 - accuracy\n",
      "Epoch 88/100\n",
      "47627/47627 [==============================] - 9s 181us/step - loss: -0.1448 - accuracy: 0.8272 - val_loss: 0.0084 - val_accuracy: 0.8295\n",
      "Epoch 89/100\n",
      "47627/47627 [==============================] - 9s 184us/step - loss: -0.1612 - accuracy: 0.8275 - val_loss: -0.0031 - val_accuracy: 0.8349\n",
      "Epoch 90/100\n",
      "47627/47627 [==============================] - 9s 187us/step - loss: -0.1777 - accuracy: 0.8284 - val_loss: -0.0147 - val_accuracy: 0.8319\n",
      "Epoch 91/100\n",
      "47627/47627 [==============================] - 9s 184us/step - loss: -0.1967 - accuracy: 0.8292 - val_loss: -0.0260 - val_accuracy: 0.8277\n",
      "Epoch 92/100\n",
      "47627/47627 [==============================] - 9s 186us/step - loss: -0.2134 - accuracy: 0.8283 - val_loss: -0.0378 - val_accuracy: 0.8267\n",
      "Epoch 93/100\n",
      "47627/47627 [==============================] - 9s 184us/step - loss: -0.2320 - accuracy: 0.8287 - val_loss: -0.0523 - val_accuracy: 0.8323\n",
      "Epoch 94/100\n",
      "47627/47627 [==============================] - 8s 160us/step - loss: -0.2514 - accuracy: 0.8291 - val_loss: -0.0647 - val_accuracy: 0.8274\n",
      "Epoch 95/100\n",
      "47627/47627 [==============================] - 4s 84us/step - loss: -0.2722 - accuracy: 0.8285 - val_loss: -0.0835 - val_accuracy: 0.8332\n",
      "Epoch 96/100\n",
      "47627/47627 [==============================] - 4s 87us/step - loss: -0.2926 - accuracy: 0.8298 - val_loss: -0.0953 - val_accuracy: 0.8311\n",
      "Epoch 97/100\n",
      "47627/47627 [==============================] - 4s 92us/step - loss: -0.3116 - accuracy: 0.8290 - val_loss: -0.1074 - val_accuracy: 0.8285\n",
      "Epoch 98/100\n",
      "47627/47627 [==============================] - 4s 93us/step - loss: -0.3317 - accuracy: 0.8300 - val_loss: -0.1227 - val_accuracy: 0.8331\n",
      "Epoch 99/100\n",
      "47627/47627 [==============================] - 5s 96us/step - loss: -0.3544 - accuracy: 0.8296 - val_loss: -0.1383 - val_accuracy: 0.8310\n",
      "Epoch 100/100\n",
      "47627/47627 [==============================] - 4s 92us/step - loss: -0.3767 - accuracy: 0.8301 - val_loss: -0.1544 - val_accuracy: 0.8286\n",
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-088f577e8541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu',input_dim = 8))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
